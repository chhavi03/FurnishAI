{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17838064",
   "metadata": {},
   "source": [
    "# NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12e24d9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 312\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>brand</th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "      <th>categories</th>\n",
       "      <th>images</th>\n",
       "      <th>manufacturer</th>\n",
       "      <th>package_dimensions</th>\n",
       "      <th>country_of_origin</th>\n",
       "      <th>material</th>\n",
       "      <th>color</th>\n",
       "      <th>uniq_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GOYMFK 1pc Free Standing Shoe Rack, Multi-laye...</td>\n",
       "      <td>GOYMFK</td>\n",
       "      <td>multiple shoes, coats, hats, and other items E...</td>\n",
       "      <td>$24.99</td>\n",
       "      <td>['Home &amp; Kitchen', 'Storage &amp; Organization', '...</td>\n",
       "      <td>['https://m.media-amazon.com/images/I/416WaLx1...</td>\n",
       "      <td>GOYMFK</td>\n",
       "      <td>2.36\"D x 7.87\"W x 21.6\"H</td>\n",
       "      <td>China</td>\n",
       "      <td>Metal</td>\n",
       "      <td>White</td>\n",
       "      <td>02593e81-5c09-5069-8516-b0b29f439ded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>subrtex Leather ding Room, Dining Chairs Set o...</td>\n",
       "      <td>subrtex</td>\n",
       "      <td>subrtex Dining chairs Set of 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>['Home &amp; Kitchen', 'Furniture', 'Dining Room F...</td>\n",
       "      <td>['https://m.media-amazon.com/images/I/31SejUEW...</td>\n",
       "      <td>Subrtex Houseware INC</td>\n",
       "      <td>18.5\"D x 16\"W x 35\"H</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sponge</td>\n",
       "      <td>Black</td>\n",
       "      <td>5938d217-b8c5-5d3e-b1cf-e28e340f292e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Plant Repotting Mat MUYETOL Waterproof Transpl...</td>\n",
       "      <td>MUYETOL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>$5.98</td>\n",
       "      <td>['Patio, Lawn &amp; Garden', 'Outdoor Décor', 'Doo...</td>\n",
       "      <td>['https://m.media-amazon.com/images/I/41RgefVq...</td>\n",
       "      <td>MUYETOL</td>\n",
       "      <td>26.8\"L x 26.8\"W</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Polyethylene</td>\n",
       "      <td>Green</td>\n",
       "      <td>b2ede786-3f51-5a45-9a5b-bcf856958cd8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title    brand  \\\n",
       "0  GOYMFK 1pc Free Standing Shoe Rack, Multi-laye...   GOYMFK   \n",
       "1  subrtex Leather ding Room, Dining Chairs Set o...  subrtex   \n",
       "2  Plant Repotting Mat MUYETOL Waterproof Transpl...  MUYETOL   \n",
       "\n",
       "                                         description   price  \\\n",
       "0  multiple shoes, coats, hats, and other items E...  $24.99   \n",
       "1                     subrtex Dining chairs Set of 2     NaN   \n",
       "2                                                NaN   $5.98   \n",
       "\n",
       "                                          categories  \\\n",
       "0  ['Home & Kitchen', 'Storage & Organization', '...   \n",
       "1  ['Home & Kitchen', 'Furniture', 'Dining Room F...   \n",
       "2  ['Patio, Lawn & Garden', 'Outdoor Décor', 'Doo...   \n",
       "\n",
       "                                              images           manufacturer  \\\n",
       "0  ['https://m.media-amazon.com/images/I/416WaLx1...                 GOYMFK   \n",
       "1  ['https://m.media-amazon.com/images/I/31SejUEW...  Subrtex Houseware INC   \n",
       "2  ['https://m.media-amazon.com/images/I/41RgefVq...                MUYETOL   \n",
       "\n",
       "         package_dimensions country_of_origin      material  color  \\\n",
       "0  2.36\"D x 7.87\"W x 21.6\"H             China         Metal  White   \n",
       "1      18.5\"D x 16\"W x 35\"H               NaN        Sponge  Black   \n",
       "2           26.8\"L x 26.8\"W               NaN  Polyethylene  Green   \n",
       "\n",
       "                                uniq_id  \n",
       "0  02593e81-5c09-5069-8516-b0b29f439ded  \n",
       "1  5938d217-b8c5-5d3e-b1cf-e28e340f292e  \n",
       "2  b2ede786-3f51-5a45-9a5b-bcf856958cd8  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, ast, re, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "CSV_PATH            = os.getenv(\"CSV_PATH\", \"intern_data_ikarus.csv\")\n",
    "PINECONE_API_KEY    = os.getenv(\"PINECONE_API_KEY\")\n",
    "PINECONE_ENV        = os.getenv(\"PINECONE_ENV\", \"us-east-1-aws\")\n",
    "PINECONE_TEXT_INDEX = os.getenv(\"PINECONE_TEXT_INDEX\", \"products-text\")\n",
    "\n",
    "assert os.path.exists(CSV_PATH), f\"CSV not found: {CSV_PATH}\"\n",
    "assert PINECONE_API_KEY, \"Missing PINECONE_API_KEY in environment\"\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "# Ensure expected columns exist\n",
    "for c in [\"uniq_id\",\"title\",\"brand\",\"description\",\"price\",\"categories\",\"material\",\"color\",\"country_of_origin\"]:\n",
    "    if c not in df.columns: df[c] = pd.NA\n",
    "\n",
    "# Basic coercions\n",
    "df[\"uniq_id\"] = df[\"uniq_id\"].astype(str)\n",
    "\n",
    "print(\"Rows:\", len(df))\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3526cc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nulls after normalization:\n",
      " title           0\n",
      "brand           0\n",
      "description     0\n",
      "price          97\n",
      "categories      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def s(x) -> str:\n",
    "    \"\"\"Safe string: None/NaN -> '', else str(x).\"\"\"\n",
    "    if x is None: return \"\"\n",
    "    if isinstance(x, float) and np.isnan(x): return \"\"\n",
    "    return str(x)\n",
    "\n",
    "def to_list(x):\n",
    "    \"\"\"Parse list-like string or comma list into a clean list[str].\"\"\"\n",
    "    xs = s(x).strip()\n",
    "    if not xs: return []\n",
    "    if xs.startswith(\"[\"):\n",
    "        try:\n",
    "            val = ast.literal_eval(xs)\n",
    "            return [s(t).strip() for t in val if s(t).strip()]\n",
    "        except Exception:\n",
    "            pass\n",
    "    return [t for t in (p.strip() for p in xs.split(\",\")) if t]\n",
    "\n",
    "def to_float(x):\n",
    "    if x is None or (isinstance(x,float) and np.isnan(x)): return np.nan\n",
    "    xs = s(x).replace(\",\", \"\").replace(\"₹\", \"\").strip()\n",
    "    m = re.findall(r\"[-+]?\\d*\\.?\\d+\", xs)\n",
    "    return float(m[0]) if m else np.nan\n",
    "\n",
    "# Normalize fields to strings / lists / floats\n",
    "if \"categories\" in df.columns:\n",
    "    df[\"categories\"] = df[\"categories\"].apply(to_list)\n",
    "\n",
    "for col in [\"title\",\"brand\",\"description\",\"material\",\"color\",\"country_of_origin\"]:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].apply(s)\n",
    "\n",
    "if \"price\" in df.columns:\n",
    "    df[\"price\"] = df[\"price\"].apply(to_float)\n",
    "\n",
    "print(\"Nulls after normalization:\\n\", df[[\"title\",\"brand\",\"description\",\"price\",\"categories\"]].isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94a9e448",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\CHHAVI\\coco\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((312, 384), 'cpu')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "text_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\", device=device)\n",
    "\n",
    "def build_text(row: dict) -> str:\n",
    "    cats = \", \".join(row.get(\"categories\", [])) if isinstance(row.get(\"categories\"), list) else \"\"\n",
    "    parts = [\n",
    "        s(row.get(\"title\")),\n",
    "        f\"brand {s(row.get('brand'))}\" if s(row.get('brand')) else \"\",\n",
    "        f\"category {cats}\" if cats else \"\",\n",
    "        f\"material {s(row.get('material'))}\" if s(row.get('material')) else \"\",\n",
    "        f\"color {s(row.get('color'))}\" if s(row.get('color')) else \"\",\n",
    "        s(row.get(\"description\")),\n",
    "    ]\n",
    "    return \" | \".join([p for p in parts if p and p.strip()])\n",
    "\n",
    "records = df.to_dict(orient=\"records\")\n",
    "texts   = [build_text(r) for r in records]\n",
    "emb     = text_model.encode(texts, normalize_embeddings=True, convert_to_numpy=True)  # (N, 384)\n",
    "\n",
    "emb.shape, device\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684ad2b7",
   "metadata": {},
   "source": [
    "# K MEANS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "794f234e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cluster_id\n",
       " 0    260\n",
       "-1     32\n",
       " 1     20\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import hdbscan\n",
    "import numpy as np\n",
    "\n",
    "USE_HDBSCAN = True  # set False to use KMeans\n",
    "\n",
    "if USE_HDBSCAN:\n",
    "    clusterer = hdbscan.HDBSCAN(min_cluster_size=8, min_samples=2, metric='euclidean')\n",
    "    labels = clusterer.fit_predict(emb)          # -1 = noise/outliers\n",
    "else:\n",
    "    K = 50  # tune per dataset size\n",
    "    labels = KMeans(n_clusters=K, n_init=\"auto\", random_state=42).fit_predict(emb)\n",
    "\n",
    "df[\"cluster_id\"] = labels\n",
    "df[\"cluster_id\"].value_counts().head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59f7068c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniq_id</th>\n",
       "      <th>title</th>\n",
       "      <th>cluster_id</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>dup_of</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02593e81-5c09-5069-8516-b0b29f439ded</td>\n",
       "      <td>GOYMFK 1pc Free Standing Shoe Rack, Multi-laye...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5938d217-b8c5-5d3e-b1cf-e28e340f292e</td>\n",
       "      <td>subrtex Leather ding Room, Dining Chairs Set o...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b2ede786-3f51-5a45-9a5b-bcf856958cd8</td>\n",
       "      <td>Plant Repotting Mat MUYETOL Waterproof Transpl...</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8fd9377b-cfa6-5f10-835c-6b8eca2816b5</td>\n",
       "      <td>Pickleball Doormat, Welcome Doormat Absorbent ...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bdc9aa30-9439-50dc-8e89-213ea211d66a</td>\n",
       "      <td>JOIN IRON Foldable TV Trays for Eating Set of ...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20da3703-26f1-53e5-aa0b-a8104527d1bb</td>\n",
       "      <td>LOVMOR 30'' Bathroom Vanity Sink Base Cabine, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>aba4138e-6401-52ca-a099-02e30b638db4</td>\n",
       "      <td>Folews Bathroom Organizer Over The Toilet Stor...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>02593e81-5c09-5069-8516-b0b29f439ded</td>\n",
       "      <td>GOYMFK 1pc Free Standing Shoe Rack, Multi-laye...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5938d217-b8c5-5d3e-b1cf-e28e340f292e</td>\n",
       "      <td>subrtex Leather ding Room, Dining Chairs Set o...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>b2ede786-3f51-5a45-9a5b-bcf856958cd8</td>\n",
       "      <td>Plant Repotting Mat MUYETOL Waterproof Transpl...</td>\n",
       "      <td>-1</td>\n",
       "      <td>False</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                uniq_id  \\\n",
       "0  02593e81-5c09-5069-8516-b0b29f439ded   \n",
       "1  5938d217-b8c5-5d3e-b1cf-e28e340f292e   \n",
       "2  b2ede786-3f51-5a45-9a5b-bcf856958cd8   \n",
       "3  8fd9377b-cfa6-5f10-835c-6b8eca2816b5   \n",
       "4  bdc9aa30-9439-50dc-8e89-213ea211d66a   \n",
       "5  20da3703-26f1-53e5-aa0b-a8104527d1bb   \n",
       "6  aba4138e-6401-52ca-a099-02e30b638db4   \n",
       "7  02593e81-5c09-5069-8516-b0b29f439ded   \n",
       "8  5938d217-b8c5-5d3e-b1cf-e28e340f292e   \n",
       "9  b2ede786-3f51-5a45-9a5b-bcf856958cd8   \n",
       "\n",
       "                                               title  cluster_id  \\\n",
       "0  GOYMFK 1pc Free Standing Shoe Rack, Multi-laye...           0   \n",
       "1  subrtex Leather ding Room, Dining Chairs Set o...           0   \n",
       "2  Plant Repotting Mat MUYETOL Waterproof Transpl...          -1   \n",
       "3  Pickleball Doormat, Welcome Doormat Absorbent ...           1   \n",
       "4  JOIN IRON Foldable TV Trays for Eating Set of ...           0   \n",
       "5  LOVMOR 30'' Bathroom Vanity Sink Base Cabine, ...           0   \n",
       "6  Folews Bathroom Organizer Over The Toilet Stor...           0   \n",
       "7  GOYMFK 1pc Free Standing Shoe Rack, Multi-laye...           0   \n",
       "8  subrtex Leather ding Room, Dining Chairs Set o...           0   \n",
       "9  Plant Repotting Mat MUYETOL Waterproof Transpl...          -1   \n",
       "\n",
       "   is_duplicate dup_of  \n",
       "0         False         \n",
       "1         False         \n",
       "2         False         \n",
       "3         False         \n",
       "4         False         \n",
       "5         False         \n",
       "6         False         \n",
       "7         False         \n",
       "8         False         \n",
       "9         False         "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "dup_flags = np.zeros(len(df), dtype=bool)\n",
    "parent_id = [\"\" for _ in range(len(df))]\n",
    "\n",
    "THRESH_DUP = 0.97  # very high similarity => duplicate\n",
    "\n",
    "for cid in sorted(set(labels)):\n",
    "    if cid == -1:\n",
    "        continue\n",
    "    idx = np.where(labels == cid)[0]\n",
    "    if len(idx) < 2:\n",
    "        continue\n",
    "    sims = cosine_similarity(emb[idx])\n",
    "    # pick the most central as representative\n",
    "    center = sims.mean(axis=1).argmax()\n",
    "    center_global = idx[center]\n",
    "    center_uid = df.iloc[center_global][\"uniq_id\"]\n",
    "    for i_local, i_global in enumerate(idx):\n",
    "        if i_global == center_global:\n",
    "            continue\n",
    "        if sims[center, i_local] >= THRESH_DUP:\n",
    "            dup_flags[i_global] = True\n",
    "            parent_id[i_global] = center_uid\n",
    "\n",
    "df[\"is_duplicate\"] = dup_flags\n",
    "df[\"dup_of\"] = parent_id\n",
    "\n",
    "df[[\"uniq_id\",\"title\",\"cluster_id\",\"is_duplicate\",\"dup_of\"]].head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "778c5fae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster_id</th>\n",
       "      <th>cluster_tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>storage cabinet, bathroom organizer, shoe orga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>door mats, door mat, doormat 18x27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cluster_id                                        cluster_tag\n",
       "0           0  storage cabinet, bathroom organizer, shoe orga...\n",
       "2          -1                                                   \n",
       "3           1                 door mats, door mat, doormat 18x27"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keybert import KeyBERT\n",
    "\n",
    "kw_model = KeyBERT(model=text_model)  # reuse encoder\n",
    "\n",
    "cluster_keywords = {}\n",
    "for cid in sorted(set(labels)):\n",
    "    idx = np.where(labels == cid)[0]\n",
    "    if cid == -1 or len(idx) < 3:\n",
    "        continue\n",
    "    # small corpus per cluster (avoid huge strings)\n",
    "    titles = df.iloc[idx][\"title\"].fillna(\"\").astype(str).tolist()\n",
    "    blob = \" \".join(titles)[:5000]\n",
    "    kw = kw_model.extract_keywords(blob, keyphrase_ngram_range=(1,2), stop_words=\"english\", top_n=8)\n",
    "    cluster_keywords[cid] = [k for (k,score) in kw]\n",
    "\n",
    "def tag_for(cid):\n",
    "    if cid in cluster_keywords and cluster_keywords[cid]:\n",
    "        return \", \".join(cluster_keywords[cid][:3])\n",
    "    return \"\"\n",
    "\n",
    "df[\"cluster_tag\"] = [tag_for(c) for c in df[\"cluster_id\"]]\n",
    "\n",
    "df[[\"cluster_id\",\"cluster_tag\"]].drop_duplicates().head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9312ce4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pinecone.update (per-id): 100%|██████████| 312/312 [01:57<00:00,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated items: 312 | Skipped (not found/errored): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from pinecone import Pinecone\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "text_index = pc.Index(PINECONE_TEXT_INDEX)\n",
    "\n",
    "def to_int_or_default(x, default=-1):\n",
    "    try:\n",
    "        return int(x)\n",
    "    except Exception:\n",
    "        return default\n",
    "\n",
    "records = df[[\"uniq_id\",\"cluster_id\",\"is_duplicate\",\"dup_of\",\"cluster_tag\"]].to_dict(orient=\"records\")\n",
    "\n",
    "updated, skipped = 0, 0\n",
    "\n",
    "for r in tqdm(records, desc=\"pinecone.update (per-id)\"):\n",
    "    uid = str(r[\"uniq_id\"])\n",
    "    meta = {\n",
    "        \"cluster_id\": to_int_or_default(r.get(\"cluster_id\"), -1),\n",
    "        \"is_duplicate\": bool(r.get(\"is_duplicate\", False)),\n",
    "        \"dup_of\": (r.get(\"dup_of\") or \"\"),\n",
    "        \"cluster_tag\": (r.get(\"cluster_tag\") or \"\")\n",
    "    }\n",
    "    try:\n",
    "        # Per-id update in v5\n",
    "        text_index.update(id=uid, set_metadata=meta, namespace=\"default\")\n",
    "        updated += 1\n",
    "    except Exception as e:\n",
    "        # Common case: id not present in this index (e.g., rows that failed ingest)\n",
    "        # You can log and continue.\n",
    "        skipped += 1\n",
    "        # print(f\"skip {uid}: {e}\")\n",
    "        continue\n",
    "    # (Optional) be gentle if your project has strict rate limits\n",
    "    # time.sleep(0.001)\n",
    "\n",
    "print(f\"Updated items: {updated} | Skipped (not found/errored): {skipped}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e9898fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6082 | Armen Living Julius 30\" Cream Faux Leather and Walnut Wood Bar Stool | cl:0.0 dup:False tag:storage cabinet, bathroom organizer, shoe organizer\n",
      "0.5851 | YuiHome Extendable Round, Farmhouse 16\" Leaf Table for Dining Room, Kitchen,Natural Wood Wash | cl:0.0 dup:False tag:storage cabinet, bathroom organizer, shoe organizer\n",
      "0.5774 | CangLong Mid Century Modern Side Chair with Wood Legs for Kitchen, Living Dining Room, Set of 1, Black | cl:0.0 dup:False tag:storage cabinet, bathroom organizer, shoe organizer\n",
      "0.5770 | VECELO Modern Industrial Style 3-Piece Dining Room Kitchen Table and Pu Cushion Chair Sets for Small Space, 2, Retro Brown | cl:0.0 dup:False tag:storage cabinet, bathroom organizer, shoe organizer\n",
      "0.5757 | Modway Baronet Button-Tufted Vegan Leather Parsons Dining Chair in Gray | cl:0.0 dup:False tag:storage cabinet, bathroom organizer, shoe organizer\n",
      "0.5691 | Leather At Home, Decorative 13 Inch Rounded Pillow Handmade from Full Grain Leather - Chair Seat, Confortable Sitting for Round Wooden/Metal Stools - Bourbon Brown | cl:0.0 dup:False tag:storage cabinet, bathroom organizer, shoe organizer\n"
     ]
    }
   ],
   "source": [
    "def preview_neighbors(q, k=5):\n",
    "    qv = text_model.encode([q], normalize_embeddings=True, convert_to_numpy=True)[0].tolist()\n",
    "    res = text_index.query(vector=qv, top_k=k, include_metadata=True, namespace=\"default\")\n",
    "    for m in res.get(\"matches\", []):\n",
    "        md = m[\"metadata\"] or {}\n",
    "        print(f\"{m['score']:.4f} | {md.get('title','')} | cl:{md.get('cluster_id')} dup:{md.get('is_duplicate')} tag:{md.get('cluster_tag')}\")\n",
    "\n",
    "preview_neighbors(\"wooden dining chair\", 6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "194da0a8",
   "metadata": {},
   "source": [
    "# CV - ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b82f70d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Products with images: 305 / 312\n"
     ]
    }
   ],
   "source": [
    "import os, ast, re, json, random, glob\n",
    "import numpy as np, pandas as pd\n",
    "from PIL import Image, ImageFile\n",
    "from tqdm.auto import tqdm\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "load_dotenv()\n",
    "\n",
    "# --- Paths / env ---\n",
    "CSV_PATH = os.getenv(\"CSV_PATH\", \"intern_data_ikarus.csv\")\n",
    "IMAGE_DIR = os.getenv(\"IMAGE_DIR\", \"./data/images_all\")  # folder/uniq_id/*.jpg|.png|.webp\n",
    "\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "PINECONE_TEXT_INDEX = os.getenv(\"PINECONE_TEXT_INDEX\", \"products-text\")\n",
    "PINECONE_IMAGE_INDEX = os.getenv(\"PINECONE_IMAGE_INDEX\", \"products-image\")\n",
    "\n",
    "assert os.path.exists(CSV_PATH), f\"CSV not found: {CSV_PATH}\"\n",
    "assert os.path.isdir(IMAGE_DIR), f\"Image dir not found: {IMAGE_DIR}\"\n",
    "assert PINECONE_API_KEY, \"Missing PINECONE_API_KEY\"\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "if \"uniq_id\" not in df.columns: raise ValueError(\"CSV must include uniq_id\")\n",
    "df[\"uniq_id\"] = df[\"uniq_id\"].astype(str)\n",
    "\n",
    "# Parse categories -> list; simple label = first category token\n",
    "def to_list(x):\n",
    "    if pd.isna(x): return []\n",
    "    xs = str(x).strip()\n",
    "    if xs.startswith(\"[\"):\n",
    "        try:\n",
    "            return [str(t).strip() for t in ast.literal_eval(xs) if str(t).strip()]\n",
    "        except Exception:\n",
    "            pass\n",
    "    return [t.strip() for t in xs.split(\",\") if t.strip()]\n",
    "\n",
    "df[\"categories\"] = df.get(\"categories\", pd.Series([pd.NA]*len(df))).apply(to_list)\n",
    "\n",
    "def primary_cat(cats):\n",
    "    if not cats: return \"unknown\"\n",
    "    return str(cats[0]).strip().lower()[:64]\n",
    "\n",
    "df[\"label\"] = df[\"categories\"].apply(primary_cat)\n",
    "\n",
    "# Map uniq_id -> image paths\n",
    "def img_paths_for(uid):\n",
    "    p = os.path.join(IMAGE_DIR, str(uid))\n",
    "    if not os.path.isdir(p): return []\n",
    "    exts = (\".jpg\",\".jpeg\",\".png\",\".webp\")\n",
    "    return [q for q in glob.glob(os.path.join(p, \"*\")) if os.path.splitext(q)[1].lower() in exts]\n",
    "\n",
    "uid_to_imgs = {uid: img_paths_for(uid) for uid in df[\"uniq_id\"].unique()}\n",
    "# Keep only uids that actually have images\n",
    "uids_with_imgs = [u for u, paths in uid_to_imgs.items() if paths]\n",
    "print(f\"Products with images: {len(uids_with_imgs)} / {len(df)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d7a414bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(482, 120, 7)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Device:\", device)\n",
    "\n",
    "# Stratify by label when possible\n",
    "df_img = df[df[\"uniq_id\"].isin(uids_with_imgs)].copy()\n",
    "labels = sorted(df_img[\"label\"].unique().tolist())\n",
    "cls2id = {c:i for i,c in enumerate(labels)}\n",
    "id2cls = {i:c for c,i in cls2id.items()}\n",
    "\n",
    "# Split by uid (not by image) to keep leakage low\n",
    "uids = df_img[\"uniq_id\"].unique().tolist()\n",
    "random.seed(42); random.shuffle(uids)\n",
    "cut = int(0.8*len(uids))\n",
    "train_uids = set(uids[:cut]); val_uids = set(uids[cut:])\n",
    "\n",
    "def collect_rows(uid_set, max_imgs_per_uid=2):\n",
    "    rows=[]\n",
    "    for uid in uid_set:\n",
    "        paths = uid_to_imgs.get(uid, [])[:max_imgs_per_uid]\n",
    "        label = df_img.loc[df_img[\"uniq_id\"]==uid, \"label\"].iloc[0]\n",
    "        for p in paths:\n",
    "            rows.append((p, cls2id[label], uid))\n",
    "    return rows\n",
    "\n",
    "train_rows = collect_rows(train_uids, max_imgs_per_uid=2)\n",
    "val_rows   = collect_rows(val_uids,   max_imgs_per_uid=2)\n",
    "\n",
    "IMG_SIZE = 224  # 224 works for ResNet/EfficientNet/ViT (patch16)\n",
    "\n",
    "train_tf = transforms.Compose([\n",
    "    transforms.Resize((256,256)),\n",
    "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.7,1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ColorJitter(0.2,0.2,0.2,0.1),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "val_tf = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "class RowsDataset(Dataset):\n",
    "    def __init__(self, rows, tf):\n",
    "        self.rows = rows\n",
    "        self.tf = tf\n",
    "    def __len__(self): return len(self.rows)\n",
    "    def __getitem__(self, i):\n",
    "        p, y, uid = self.rows[i]\n",
    "        im = Image.open(p).convert(\"RGB\")\n",
    "        im = self.tf(im)\n",
    "        return im, y, uid\n",
    "\n",
    "train_ds = RowsDataset(train_rows, train_tf)\n",
    "\n",
    "val_ds   = RowsDataset(val_rows,   val_tf)\n",
    "train_dl = DataLoader(train_ds, batch_size=32, shuffle=True,  num_workers=0, pin_memory=False)\n",
    "val_dl   = DataLoader(val_ds,   batch_size=64, shuffle=False, num_workers=0, pin_memory=False)\n",
    "\n",
    "len(train_ds), len(val_ds), len(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7ccac211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Backbone: resnet18 | Params: 11.18M\n"
     ]
    }
   ],
   "source": [
    "import timm, torch.nn as nn, torch\n",
    "\n",
    "# Options:\n",
    "#   \"resnet18\", \"efficientnet_b0\", \"vit_base_patch16_224\", \"convnext_tiny\"\n",
    "BACKBONE = os.getenv(\"BACKBONE\", \"resnet18\")\n",
    "\n",
    "def build_model(backbone: str, num_classes: int):\n",
    "    m = timm.create_model(backbone, pretrained=True, num_classes=num_classes)\n",
    "    return m\n",
    "\n",
    "model = build_model(BACKBONE, num_classes=len(labels)).to(device)\n",
    "print(f\"Backbone: {BACKBONE} | Params: {sum(p.numel() for p in model.parameters())/1e6:.2f}M\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5c9f5f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6 | train 1.6536/0.585 | val 1.0976/0.925 | 58.7s\n",
      "Epoch 2/6 | train 1.0123/0.790 | val 0.5586/0.925 | 48.1s\n",
      "Epoch 3/6 | train 0.7581/0.790 | val 0.4640/0.925 | 47.5s\n",
      "Epoch 4/6 | train 0.6764/0.790 | val 0.4306/0.925 | 47.1s\n",
      "Epoch 5/6 | train 0.6039/0.790 | val 0.3631/0.925 | 48.5s\n",
      "Epoch 6/6 | train 0.5392/0.793 | val 0.3423/0.925 | 48.4s\n",
      "Best val: 0.34232182999451954 acc: 0.925\n"
     ]
    }
   ],
   "source": [
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import torch.optim as optim\n",
    "import math, time\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-4)\n",
    "scaler = GradScaler(enabled=(device==\"cuda\"))\n",
    "\n",
    "def run_epoch(dl, train=True):\n",
    "    model.train(train)\n",
    "    total, correct, loss_sum = 0, 0, 0.0\n",
    "    for x, y, _ in dl:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        if train: optimizer.zero_grad(set_to_none=True)\n",
    "        with autocast(enabled=(device==\"cuda\")):\n",
    "            logits = model(x)\n",
    "            loss = criterion(logits, y)\n",
    "        if train:\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        loss_sum += loss.item() * x.size(0)\n",
    "        pred = logits.argmax(1)\n",
    "        correct += (pred==y).sum().item()\n",
    "        total += x.size(0)\n",
    "    return loss_sum/total, correct/total\n",
    "\n",
    "best_val = math.inf\n",
    "best_acc = 0.0\n",
    "patience, patience_ctr = 3, 0\n",
    "\n",
    "os.makedirs(\"./models\", exist_ok=True)\n",
    "\n",
    "EPOCHS = 6\n",
    "for e in range(1, EPOCHS+1):\n",
    "    t0=time.time()\n",
    "    tr_loss, tr_acc = run_epoch(train_dl, True)\n",
    "    va_loss, va_acc = run_epoch(val_dl, False)\n",
    "    dt = time.time()-t0\n",
    "    print(f\"Epoch {e}/{EPOCHS} | train {tr_loss:.4f}/{tr_acc:.3f} | val {va_loss:.4f}/{va_acc:.3f} | {dt:.1f}s\")\n",
    "\n",
    "    if va_loss < best_val:\n",
    "        best_val = va_loss\n",
    "        best_acc = va_acc\n",
    "        torch.save({\n",
    "            \"backbone\": BACKBONE,\n",
    "            \"state_dict\": model.state_dict(),\n",
    "            \"labels\": labels,\n",
    "            \"img_size\": IMG_SIZE\n",
    "        }, f\"./models/cv_{BACKBONE}.pt\")\n",
    "        patience_ctr = 0\n",
    "    else:\n",
    "        patience_ctr += 1\n",
    "        if patience_ctr >= patience:\n",
    "            print(\"Early stopping.\")\n",
    "            break\n",
    "\n",
    "print(\"Best val:\", best_val, \"acc:\", best_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2fcf492a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load best weights (optional if you just trained)\n",
    "ckpt_path = f\"./models/cv_{BACKBONE}.pt\"\n",
    "ckpt = torch.load(ckpt_path, map_location=device)\n",
    "model.load_state_dict(ckpt[\"state_dict\"])\n",
    "model.eval()\n",
    "\n",
    "import torchvision.transforms as T\n",
    "infer_tf = T.Compose([T.Resize((IMG_SIZE, IMG_SIZE)), T.ToTensor()])\n",
    "\n",
    "@torch.inference_mode()\n",
    "def predict_paths(paths):\n",
    "    outs=[]\n",
    "    for p in paths:\n",
    "        try:\n",
    "            im = Image.open(p).convert(\"RGB\")\n",
    "            x = infer_tf(im).unsqueeze(0).to(device)\n",
    "            logits = model(x)\n",
    "            prob = torch.softmax(logits, dim=1).squeeze(0).cpu().numpy()\n",
    "            i = int(prob.argmax())\n",
    "            outs.append((p, labels[i], float(prob[i])))\n",
    "        except Exception as e:\n",
    "            outs.append((p, \"unknown\", 0.0))\n",
    "    return outs\n",
    "\n",
    "def classify_uid(uid: str, max_imgs=4):\n",
    "    paths = uid_to_imgs.get(uid, [])[:max_imgs]\n",
    "    if not paths: return \"unknown\", 0.0\n",
    "    preds = predict_paths(paths)\n",
    "    # Majority vote with confidence as tiebreaker\n",
    "    counts, confs = {}, {}\n",
    "    for p, cls, prob in preds:\n",
    "        counts[cls]=counts.get(cls,0)+1\n",
    "        confs[cls]=max(confs.get(cls,0.0), prob)\n",
    "    cls = max(counts, key=lambda c: (counts[c], confs[c]))\n",
    "    return cls, confs[cls]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b1cd60c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "classify: 100%|██████████| 305/305 [01:08<00:00,  4.44it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniq_id</th>\n",
       "      <th>predicted_category</th>\n",
       "      <th>pred_conf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02593e81-5c09-5069-8516-b0b29f439ded</td>\n",
       "      <td>home &amp; kitchen</td>\n",
       "      <td>0.952235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5938d217-b8c5-5d3e-b1cf-e28e340f292e</td>\n",
       "      <td>home &amp; kitchen</td>\n",
       "      <td>0.998851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b2ede786-3f51-5a45-9a5b-bcf856958cd8</td>\n",
       "      <td>home &amp; kitchen</td>\n",
       "      <td>0.673488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8fd9377b-cfa6-5f10-835c-6b8eca2816b5</td>\n",
       "      <td>home &amp; kitchen</td>\n",
       "      <td>0.780289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bdc9aa30-9439-50dc-8e89-213ea211d66a</td>\n",
       "      <td>home &amp; kitchen</td>\n",
       "      <td>0.988293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                uniq_id predicted_category  pred_conf\n",
       "0  02593e81-5c09-5069-8516-b0b29f439ded     home & kitchen   0.952235\n",
       "1  5938d217-b8c5-5d3e-b1cf-e28e340f292e     home & kitchen   0.998851\n",
       "2  b2ede786-3f51-5a45-9a5b-bcf856958cd8     home & kitchen   0.673488\n",
       "3  8fd9377b-cfa6-5f10-835c-6b8eca2816b5     home & kitchen   0.780289\n",
       "4  bdc9aa30-9439-50dc-8e89-213ea211d66a     home & kitchen   0.988293"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = []\n",
    "for uid in tqdm(uids_with_imgs, desc=\"classify\"):\n",
    "    cls, prob = classify_uid(uid, max_imgs=4)\n",
    "    predicted.append({\"uniq_id\": uid, \"predicted_category\": cls, \"pred_conf\": prob})\n",
    "\n",
    "pred_df = pd.DataFrame(predicted)\n",
    "pred_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7de25d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "update products-image: 100%|██████████| 305/305 [02:02<00:00,  2.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "products-image: updated=305 skipped=0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "update products-text: 100%|██████████| 305/305 [01:58<00:00,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "products-text: updated=305 skipped=0\n",
      "Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from pinecone import Pinecone\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "img_index  = pc.Index(PINECONE_IMAGE_INDEX)\n",
    "text_index = pc.Index(PINECONE_TEXT_INDEX)\n",
    "\n",
    "def update_meta(index, recs, label: str, namespace: str = \"default\"):\n",
    "    updated, skipped = 0, 0\n",
    "    for r in tqdm(recs, desc=f\"update {label}\"):\n",
    "        uid = str(r[\"uniq_id\"])\n",
    "        meta = {\n",
    "            \"predicted_category\": r.get(\"predicted_category\", \"\") or \"\",\n",
    "            \"pred_conf\": float(r.get(\"pred_conf\", 0.0)),\n",
    "        }\n",
    "        try:\n",
    "            index.update(id=uid, set_metadata=meta, namespace=namespace)\n",
    "            updated += 1\n",
    "        except Exception:\n",
    "            skipped += 1\n",
    "            # you can log the exception here if you want\n",
    "            # print(f\"skip {uid}: {e}\")\n",
    "            continue\n",
    "    print(f\"{label}: updated={updated} skipped={skipped}\")\n",
    "\n",
    "update_meta(img_index,  predicted, label=PINECONE_IMAGE_INDEX)\n",
    "update_meta(text_index, predicted, label=PINECONE_TEXT_INDEX)\n",
    "\n",
    "print(\"Done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ca1e502b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample uid: 91688563-4731-5976-bc36-85e98ca7ba1a\n",
      "paths: ['./data/images_all\\\\91688563-4731-5976-bc36-85e98ca7ba1a\\\\000_eceafd48.jpg', './data/images_all\\\\91688563-4731-5976-bc36-85e98ca7ba1a\\\\001_474d31f7.jpg']\n",
      "pred: ('home & kitchen', 0.9946603178977966)\n"
     ]
    }
   ],
   "source": [
    "sample_uid = random.choice(uids_with_imgs)\n",
    "print(\"sample uid:\", sample_uid)\n",
    "print(\"paths:\", uid_to_imgs[sample_uid][:2])\n",
    "print(\"pred:\", classify_uid(sample_uid))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
