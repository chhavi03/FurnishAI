{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3f55c803",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, math, re, ast, asyncio, aiohttp, hashlib, io\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Any, Optional\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "from tenacity import retry, stop_after_attempt, wait_exponential\n",
    "from dotenv import load_dotenv\n",
    "from PIL import Image\n",
    "from rapidfuzz import process, fuzz\n",
    "\n",
    "# ---- env ----\n",
    "load_dotenv()\n",
    "\n",
    "# Required: Pinecone and (optionally) OpenAI if you want OpenAI embeddings instead of local ST\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "PINECONE_ENV      = os.getenv(\"PINECONE_ENV\", \"us-east-1-aws\")\n",
    "PINECONE_TEXT_INDEX = os.getenv(\"PINECONE_TEXT_INDEX\", \"products-text\")\n",
    "EMBED_PROVIDER    = os.getenv(\"EMBED_PROVIDER\", \"local\")\n",
    "\n",
    "# Paths\n",
    "CSV_PATH          = os.getenv(\"CSV_PATH\", \"intern_data_ikarus.csv\")  # set this path\n",
    "IMAGE_DIR         = os.getenv(\"IMAGE_DIR\", \"./data/images\")          # will be created\n",
    "os.makedirs(IMAGE_DIR, exist_ok=True)\n",
    "\n",
    "assert PINECONE_API_KEY, \"Set PINECONE_API_KEY in .env\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2c04b5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load\n",
    "df_raw = pd.read_csv(CSV_PATH)\n",
    "\n",
    "# Keep only expected columns (add if any missing)\n",
    "expected_cols = [\"uniq_id\",\"title\",\"brand\",\"description\",\"price\",\"categories\",\"images\",\n",
    "                 \"manufacturer\",\"package_dimensions\",\"country_of_origin\",\"material\",\"color\"]\n",
    "for c in expected_cols:\n",
    "    if c not in df_raw.columns:\n",
    "        df_raw[c] = pd.NA\n",
    "\n",
    "df = df_raw[expected_cols].copy()\n",
    "\n",
    "# Normalize types\n",
    "def to_list(x):\n",
    "    if pd.isna(x): return []\n",
    "    sx = str(x).strip()\n",
    "    if sx.startswith('['):  # JSON-like\n",
    "        try: return list(ast.literal_eval(sx))\n",
    "        except: pass\n",
    "    # fallback: comma-separated\n",
    "    return [s.strip() for s in sx.split(\",\") if s.strip()]\n",
    "\n",
    "def to_float(x):\n",
    "    if pd.isna(x): return pd.NA\n",
    "    try:\n",
    "        s = str(x).replace(\",\",\"\").replace(\"₹\",\"\").strip()\n",
    "        return float(re.findall(r\"[-+]?\\d*\\.?\\d+\", s)[0]) if re.findall(r\"[-+]?\\d*\\.?\\d+\", s) else pd.NA\n",
    "    except:\n",
    "        return pd.NA\n",
    "\n",
    "df[\"categories\"] = df[\"categories\"].apply(to_list)\n",
    "df[\"images\"]     = df[\"images\"].apply(to_list)\n",
    "df[\"price\"]      = df[\"price\"].apply(to_float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0e6f74d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>missing_ratio</th>\n",
       "      <th>count_missing</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>country_of_origin</th>\n",
       "      <td>0.599359</td>\n",
       "      <td>187</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>description</th>\n",
       "      <td>0.490385</td>\n",
       "      <td>153</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>manufacturer</th>\n",
       "      <td>0.342949</td>\n",
       "      <td>107</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>0.310897</td>\n",
       "      <td>97</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>material</th>\n",
       "      <td>0.301282</td>\n",
       "      <td>94</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>color</th>\n",
       "      <td>0.150641</td>\n",
       "      <td>47</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>package_dimensions</th>\n",
       "      <td>0.019231</td>\n",
       "      <td>6</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uniq_id</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brand</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categories</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>images</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    missing_ratio  count_missing    n\n",
       "country_of_origin        0.599359            187  312\n",
       "description              0.490385            153  312\n",
       "manufacturer             0.342949            107  312\n",
       "price                    0.310897             97  312\n",
       "material                 0.301282             94  312\n",
       "color                    0.150641             47  312\n",
       "package_dimensions       0.019231              6  312\n",
       "uniq_id                  0.000000              0  312\n",
       "title                    0.000000              0  312\n",
       "brand                    0.000000              0  312\n",
       "categories               0.000000              0  312\n",
       "images                   0.000000              0  312"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missing_summary = df.isna().mean().sort_values(ascending=False).to_frame(\"missing_ratio\")\n",
    "missing_summary[\"count_missing\"] = df.isna().sum()\n",
    "missing_summary[\"n\"] = len(df)\n",
    "missing_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "13742d6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\CHHAVI\\coco\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "e:\\CHHAVI\\coco\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "e:\\CHHAVI\\coco\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "e:\\CHHAVI\\coco\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "e:\\CHHAVI\\coco\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "e:\\CHHAVI\\coco\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "e:\\CHHAVI\\coco\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "e:\\CHHAVI\\coco\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "e:\\CHHAVI\\coco\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "e:\\CHHAVI\\coco\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "e:\\CHHAVI\\coco\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "e:\\CHHAVI\\coco\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "e:\\CHHAVI\\coco\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "e:\\CHHAVI\\coco\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "e:\\CHHAVI\\coco\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "e:\\CHHAVI\\coco\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "e:\\CHHAVI\\coco\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "e:\\CHHAVI\\coco\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "e:\\CHHAVI\\coco\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "e:\\CHHAVI\\coco\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "e:\\CHHAVI\\coco\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "e:\\CHHAVI\\coco\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "e:\\CHHAVI\\coco\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "e:\\CHHAVI\\coco\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "e:\\CHHAVI\\coco\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "e:\\CHHAVI\\coco\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "e:\\CHHAVI\\coco\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "e:\\CHHAVI\\coco\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "e:\\CHHAVI\\coco\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "e:\\CHHAVI\\coco\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "e:\\CHHAVI\\coco\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "e:\\CHHAVI\\coco\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "e:\\CHHAVI\\coco\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "e:\\CHHAVI\\coco\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "e:\\CHHAVI\\coco\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "e:\\CHHAVI\\coco\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "e:\\CHHAVI\\coco\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "e:\\CHHAVI\\coco\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "e:\\CHHAVI\\coco\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "e:\\CHHAVI\\coco\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "e:\\CHHAVI\\coco\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "e:\\CHHAVI\\coco\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "e:\\CHHAVI\\coco\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "e:\\CHHAVI\\coco\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "e:\\CHHAVI\\coco\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "e:\\CHHAVI\\coco\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "e:\\CHHAVI\\coco\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "e:\\CHHAVI\\coco\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "e:\\CHHAVI\\coco\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "e:\\CHHAVI\\coco\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "e:\\CHHAVI\\coco\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "e:\\CHHAVI\\coco\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "e:\\CHHAVI\\coco\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "e:\\CHHAVI\\coco\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "e:\\CHHAVI\\coco\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "e:\\CHHAVI\\coco\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "e:\\CHHAVI\\coco\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "e:\\CHHAVI\\coco\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "e:\\CHHAVI\\coco\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "e:\\CHHAVI\\coco\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "e:\\CHHAVI\\coco\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "e:\\CHHAVI\\coco\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "e:\\CHHAVI\\coco\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "e:\\CHHAVI\\coco\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "e:\\CHHAVI\\coco\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "e:\\CHHAVI\\coco\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "e:\\CHHAVI\\coco\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "e:\\CHHAVI\\coco\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "e:\\CHHAVI\\coco\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n",
      "e:\\CHHAVI\\coco\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1215: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis, out=out, keepdims=keepdims)\n"
     ]
    }
   ],
   "source": [
    "# Categorical mode with fallback\n",
    "def mode_or_na(series: pd.Series):\n",
    "    vc = series.dropna().astype(str).value_counts()\n",
    "    return vc.idxmax() if not vc.empty else pd.NA\n",
    "\n",
    "# Price imputation: median by (brand, primary_category) -> then by primary_category -> global median\n",
    "df[\"primary_category\"] = df[\"categories\"].apply(lambda lst: (lst[0] if lst else pd.NA))\n",
    "\n",
    "price_global = df[\"price\"].median(skipna=True)\n",
    "brand_cat_med = df.groupby([\"brand\",\"primary_category\"])[\"price\"].median().dropna()\n",
    "cat_med = df.groupby([\"primary_category\"])[\"price\"].median().dropna()\n",
    "\n",
    "def impute_price(row):\n",
    "    if not pd.isna(row[\"price\"]):\n",
    "        return row[\"price\"]\n",
    "    key = (row[\"brand\"], row[\"primary_category\"])\n",
    "    if key in brand_cat_med:\n",
    "        return float(brand_cat_med[key])\n",
    "    if row[\"primary_category\"] in cat_med:\n",
    "        return float(cat_med[row[\"primary_category\"]])\n",
    "    return float(price_global) if not math.isnan(price_global) else 0.0\n",
    "\n",
    "df[\"price\"] = df.apply(impute_price, axis=1)\n",
    "\n",
    "# Brand impute (use manufacturer or title hint)\n",
    "brand_mode = mode_or_na(df[\"brand\"])\n",
    "def impute_brand(row):\n",
    "    b = row[\"brand\"]\n",
    "    if pd.isna(b) or str(b).strip()==\"\":\n",
    "        cand = row.get(\"manufacturer\")\n",
    "        if pd.notna(cand) and str(cand).strip()!=\"\":\n",
    "            return str(cand).strip()\n",
    "        # fuzzy extract from title using frequent brands (top 100)\n",
    "        common = df[\"brand\"].dropna().astype(str).str.strip().value_counts().head(100).index.tolist()\n",
    "        title = str(row.get(\"title\",\"\"))\n",
    "        match, score, _ = process.extractOne(title, common, scorer=fuzz.partial_ratio) if common else (None,0,None)\n",
    "        if score>=85: return match\n",
    "        return brand_mode\n",
    "    return b\n",
    "\n",
    "df[\"brand\"] = df.apply(impute_brand, axis=1).astype(str).str.strip()\n",
    "\n",
    "# Description impute\n",
    "def impute_desc(row):\n",
    "    d = row[\"description\"]\n",
    "    if pd.notna(d) and str(d).strip()!=\"\":\n",
    "        return str(d).strip()\n",
    "    bits = [str(row.get(\"title\",\"\")).strip(), str(row.get(\"brand\",\"\")).strip()]\n",
    "    cats = \", \".join(row.get(\"categories\", []))\n",
    "    if cats: bits.append(cats)\n",
    "    return \" - \".join([b for b in bits if b])\n",
    "df[\"description\"] = df.apply(impute_desc, axis=1)\n",
    "\n",
    "# Material, Color impute (simple: mode per primary_category, else global mode)\n",
    "mat_mode_global = mode_or_na(df[\"material\"])\n",
    "col_mode_global = mode_or_na(df[\"color\"])\n",
    "mat_mode_by_cat = df.groupby(\"primary_category\")[\"material\"].agg(mode_or_na)\n",
    "col_mode_by_cat = df.groupby(\"primary_category\")[\"color\"].agg(mode_or_na)\n",
    "\n",
    "def impute_by_cat(row, col, by_cat, global_mode):\n",
    "    v = row[col]\n",
    "    if pd.notna(v) and str(v).strip()!=\"\":\n",
    "        return str(v).strip()\n",
    "    cat = row[\"primary_category\"]\n",
    "    if pd.notna(cat) and cat in by_cat and pd.notna(by_cat[cat]):\n",
    "        return str(by_cat[cat]).strip()\n",
    "    return str(global_mode) if pd.notna(global_mode) else \"\"\n",
    "\n",
    "df[\"material\"] = df.apply(lambda r: impute_by_cat(r,\"material\", mat_mode_by_cat, mat_mode_global), axis=1)\n",
    "df[\"color\"]    = df.apply(lambda r: impute_by_cat(r,\"color\",    col_mode_by_cat, col_mode_global), axis=1)\n",
    "\n",
    "# Package dimensions: normalize to a canonical string \"L x W x H (units)\" if possible; else keep\n",
    "def clean_dims(x):\n",
    "    if pd.isna(x): return \"\"\n",
    "    s = str(x).lower().strip()\n",
    "    s = s.replace(\"×\",\"x\").replace(\"*\",\"x\")\n",
    "    return re.sub(r\"\\s+\", \" \", s)\n",
    "df[\"package_dimensions\"] = df[\"package_dimensions\"].apply(clean_dims)\n",
    "\n",
    "# Country: fill with mode\n",
    "df[\"country_of_origin\"] = df[\"country_of_origin\"].fillna(mode_or_na(df[\"country_of_origin\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "20684a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 312 | with image: 312 | without image: 0\n"
     ]
    }
   ],
   "source": [
    "# --- FIX CELL: ensure primary_image and has_image exist ---\n",
    "\n",
    "import re, ast\n",
    "from typing import List\n",
    "\n",
    "def _to_list(x):\n",
    "    if x is None or (isinstance(x, float) and pd.isna(x)): return []\n",
    "    s = str(x).strip()\n",
    "    if s.startswith('['):\n",
    "        try: return list(ast.literal_eval(s))\n",
    "        except: pass\n",
    "    return [t.strip() for t in s.split(\",\") if t.strip()]\n",
    "\n",
    "def _is_url(s: str) -> bool:\n",
    "    return bool(re.match(r'^https?://', s or \"\", re.I))\n",
    "\n",
    "def _pick_primary_image(img_list: List[str]) -> str:\n",
    "    exts = (\".jpg\",\".jpeg\",\".png\",\".webp\")\n",
    "    for u in img_list:\n",
    "        if _is_url(u) and any(u.lower().split(\"?\")[0].endswith(e) for e in exts):\n",
    "            return u\n",
    "    for u in img_list:\n",
    "        if _is_url(u):\n",
    "            return u\n",
    "    return \"\"\n",
    "\n",
    "# Make sure required columns exist\n",
    "for col in [\"images\", \"primary_image\", \"has_image\"]:\n",
    "    if col not in df.columns:\n",
    "        df[col] = pd.NA\n",
    "\n",
    "# Normalize images to list\n",
    "df[\"images\"] = df[\"images\"].apply(_to_list)\n",
    "\n",
    "# (Re)compute primary_image and has_image\n",
    "df[\"primary_image\"] = df[\"images\"].apply(_pick_primary_image)\n",
    "df[\"has_image\"] = df[\"primary_image\"].apply(lambda s: bool(s))\n",
    "\n",
    "# Optional quick sanity print\n",
    "print(\"Rows:\", len(df),\n",
    "      \"| with image:\", int(df[\"has_image\"].sum()),\n",
    "      \"| without image:\", int((~df[\"has_image\"]).sum()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "33685ea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rows with primary_image: 312\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "primary_image\n",
       "m.media-amazon.com    312\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib.parse import urlparse\n",
    "import pandas as pd\n",
    "\n",
    "# Count images we *intend* to download\n",
    "candidates = df[df[\"has_image\"]].copy()\n",
    "print(\"rows with primary_image:\", len(candidates))\n",
    "\n",
    "# Domain stats (helps spot hosts that block bots)\n",
    "domains = (\n",
    "    candidates[\"primary_image\"]\n",
    "    .dropna().astype(str)\n",
    "    .apply(lambda u: urlparse(u).netloc.lower())\n",
    "    .value_counts()\n",
    "    .head(15)\n",
    ")\n",
    "domains\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "837f05d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniq_id</th>\n",
       "      <th>primary_image</th>\n",
       "      <th>image_candidates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02593e81-5c09-5069-8516-b0b29f439ded</td>\n",
       "      <td>https://m.media-amazon.com/images/I/416WaLx10j...</td>\n",
       "      <td>[https://m.media-amazon.com/images/I/416WaLx10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5938d217-b8c5-5d3e-b1cf-e28e340f292e</td>\n",
       "      <td>https://m.media-amazon.com/images/I/31SejUEWY7...</td>\n",
       "      <td>[https://m.media-amazon.com/images/I/31SejUEWY...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b2ede786-3f51-5a45-9a5b-bcf856958cd8</td>\n",
       "      <td>https://m.media-amazon.com/images/I/41RgefVq70...</td>\n",
       "      <td>[https://m.media-amazon.com/images/I/41RgefVq7...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                uniq_id  \\\n",
       "0  02593e81-5c09-5069-8516-b0b29f439ded   \n",
       "1  5938d217-b8c5-5d3e-b1cf-e28e340f292e   \n",
       "2  b2ede786-3f51-5a45-9a5b-bcf856958cd8   \n",
       "\n",
       "                                       primary_image  \\\n",
       "0  https://m.media-amazon.com/images/I/416WaLx10j...   \n",
       "1  https://m.media-amazon.com/images/I/31SejUEWY7...   \n",
       "2  https://m.media-amazon.com/images/I/41RgefVq70...   \n",
       "\n",
       "                                    image_candidates  \n",
       "0  [https://m.media-amazon.com/images/I/416WaLx10...  \n",
       "1  [https://m.media-amazon.com/images/I/31SejUEWY...  \n",
       "2  [https://m.media-amazon.com/images/I/41RgefVq7...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from typing import List\n",
    "\n",
    "def is_url(s: str) -> bool:\n",
    "    return bool(re.match(r'^https?://', s or \"\", re.I))\n",
    "\n",
    "PREFERRED_EXTS = (\".jpg\",\".jpeg\",\".png\",\".webp\",\".bmp\")\n",
    "\n",
    "def best_image_candidates(img_list: List[str]) -> List[str]:\n",
    "    \"\"\"Return a prioritized list of image URLs from the product's images array.\"\"\"\n",
    "    if not isinstance(img_list, list):\n",
    "        img_list = []\n",
    "    cleaned = []\n",
    "    for u in img_list:\n",
    "        if not isinstance(u, str):\n",
    "            continue\n",
    "        u = u.strip().strip('\"').strip(\"'\")\n",
    "        if is_url(u):\n",
    "            cleaned.append(u)\n",
    "    # 1) URLs with preferred extensions first\n",
    "    pref = [u for u in cleaned if any(u.lower().split(\"?\")[0].endswith(ext) for ext in PREFERRED_EXTS)]\n",
    "    # 2) Then any remaining valid URL (some servers hide extension)\n",
    "    others = [u for u in cleaned if u not in pref]\n",
    "    return pref + others\n",
    "\n",
    "# Build per-row candidate lists\n",
    "df[\"image_candidates\"] = df[\"images\"].apply(best_image_candidates)\n",
    "\n",
    "# sanity\n",
    "df[[\"uniq_id\",\"primary_image\",\"image_candidates\"]].head(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9e7e3c",
   "metadata": {},
   "source": [
    "# IMAGE DOWNLOAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "617c56e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re, io, ast, hashlib, asyncio, aiohttp, random, string\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Any\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "from tenacity import retry, stop_after_attempt, wait_exponential\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# ⬅️ set these\n",
    "CSV_PATH  = os.getenv(\"CSV_PATH\", \"intern_data_ikarus.csv\")\n",
    "IMAGE_DIR = os.getenv(\"IMAGE_DIR\", \"./data/images_all\")\n",
    "\n",
    "os.makedirs(IMAGE_DIR, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6ed9333d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 312 | total image URLs found: 1966\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(CSV_PATH)\n",
    "\n",
    "# Ensure expected cols exist\n",
    "for c in [\"uniq_id\",\"images\"]:\n",
    "    if c not in df.columns: df[c] = pd.NA\n",
    "\n",
    "def to_list(x):\n",
    "    if pd.isna(x): return []\n",
    "    s = str(x).strip()\n",
    "    if s.startswith('['):\n",
    "        try:\n",
    "            v = ast.literal_eval(s)\n",
    "            return [str(u).strip() for u in v if str(u).strip()]\n",
    "        except:\n",
    "            pass\n",
    "    return [u.strip() for u in s.split(\",\") if u.strip()]\n",
    "\n",
    "df[\"images_list\"] = df[\"images\"].apply(to_list)\n",
    "\n",
    "total_expected = int(df[\"images_list\"].apply(len).sum())\n",
    "print(\"Rows:\", len(df), \"| total image URLs found:\", total_expected)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605c60a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Planned downloads: 1966  (will skip already-downloaded files)\n"
     ]
    }
   ],
   "source": [
    "def is_url(s: str) -> bool:\n",
    "    return bool(re.match(r\"^https?://\", s or \"\", re.I))\n",
    "\n",
    "@dataclass\n",
    "class ImageTask:\n",
    "    uniq_id: str\n",
    "    idx: int\n",
    "    url: str\n",
    "    out_path: str\n",
    "\n",
    "def file_name(uniq_id: str, idx: int, url: str) -> str:\n",
    "    base = os.path.splitext(url.split(\"?\")[0])[1].lower()\n",
    "    ext = base if base in [\".jpg\",\".jpeg\",\".png\",\".webp\"] else \".jpg\"\n",
    "    h = hashlib.md5(url.encode(\"utf-8\")).hexdigest()[:8]\n",
    "    return f\"{idx:03d}_{h}{ext}\"\n",
    "\n",
    "tasks: List[ImageTask] = []\n",
    "for _, row in df.iterrows():\n",
    "    uid = str(row.get(\"uniq_id\",\"unknown\"))\n",
    "    imgs = [u for u in row[\"images_list\"] if is_url(u)]\n",
    "    if not imgs:\n",
    "        continue\n",
    "    out_dir = os.path.join(IMAGE_DIR, uid)\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    for i, url in enumerate(imgs):\n",
    "        out_path = os.path.join(out_dir, file_name(uid, i, url))\n",
    "        if not os.path.exists(out_path):\n",
    "            tasks.append(ImageTask(uniq_id=uid, idx=i, url=url, out_path=out_path))\n",
    "\n",
    "print(\"Planned downloads:\", len(tasks), \" (will skip already-downloaded files)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc2d205",
   "metadata": {},
   "outputs": [],
   "source": [
    "UA_LIST = [\n",
    "    # a few realistic UAs\n",
    "    \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\",\n",
    "    \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.0 Safari/605.1.15\",\n",
    "    \"Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\",\n",
    "]\n",
    "\n",
    "def rand_headers(url: str) -> Dict[str,str]:\n",
    "    return {\n",
    "        \"User-Agent\": random.choice(UA_LIST),\n",
    "        \"Accept\": \"image/avif,image/webp,image/apng,image/svg+xml,image/*;q=0.8,*/*;q=0.5\",\n",
    "        \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "        \"Referer\": f\"https://{re.sub(r'^https?://','',url).split('/')[0]}/\",\n",
    "        \"Cache-Control\": \"no-cache\",\n",
    "        \"Pragma\": \"no-cache\",\n",
    "    }\n",
    "\n",
    "def ensure_ext(path: str, content_type: str) -> str:\n",
    "    if content_type:\n",
    "        ct = content_type.lower().split(\";\")[0]\n",
    "        if ct.endswith(\"jpeg\") or ct.endswith(\"jpg\"):\n",
    "            return os.path.splitext(path)[0] + \".jpg\"\n",
    "        if ct.endswith(\"png\"):\n",
    "            return os.path.splitext(path)[0] + \".png\"\n",
    "        if ct.endswith(\"webp\"):\n",
    "            return os.path.splitext(path)[0] + \".webp\"\n",
    "    return path\n",
    "\n",
    "@retry(stop=stop_after_attempt(4), wait=wait_exponential(multiplier=0.6, min=0.6, max=6))\n",
    "async def fetch_and_save(session: aiohttp.ClientSession, task: ImageTask) -> bool:\n",
    "    async with session.get(task.url, headers=rand_headers(task.url), allow_redirects=True) as resp:\n",
    "        if resp.status != 200:\n",
    "            raise RuntimeError(f\"HTTP {resp.status}\")\n",
    "        ctype = resp.headers.get(\"Content-Type\",\"\").lower()\n",
    "        raw = await resp.read()\n",
    "        # Validate & normalize\n",
    "        try:\n",
    "            im = Image.open(io.BytesIO(raw))\n",
    "            im = im.convert(\"RGB\") if im.mode not in (\"RGB\",\"L\") else im\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Not an image or corrupt: {e}\")\n",
    "        out_path = ensure_ext(task.out_path, ctype)\n",
    "        # Save (JPEG for non-lossless; preserve PNG if originally PNG)\n",
    "        ext = os.path.splitext(out_path)[1].lower()\n",
    "        if ext == \".png\":\n",
    "            im.save(out_path, format=\"PNG\", optimize=True)\n",
    "        elif ext == \".webp\":\n",
    "            im.save(out_path, format=\"WEBP\", quality=90, method=4)\n",
    "        else:\n",
    "            im.save(out_path, format=\"JPEG\", quality=92, optimize=True)\n",
    "        return True\n",
    "\n",
    "async def run_download(tasks: List[ImageTask], concurrency: int = 24, per_host: int = 8, timeout_s: int = 20):\n",
    "    timeout = aiohttp.ClientTimeout(total=timeout_s)\n",
    "    connector = aiohttp.TCPConnector(limit=concurrency, limit_per_host=per_host, ttl_dns_cache=300)\n",
    "    success = 0\n",
    "    failed: List[ImageTask] = []\n",
    "\n",
    "    pbar = tqdm(total=len(tasks), desc=\"downloading images\")\n",
    "    async with aiohttp.ClientSession(timeout=timeout, connector=connector) as session:\n",
    "        sem = asyncio.Semaphore(concurrency)\n",
    "        async def worker(t: ImageTask):\n",
    "            nonlocal success\n",
    "            async with sem:\n",
    "                try:\n",
    "                    ok = await fetch_and_save(session, t)\n",
    "                    if ok: success += 1\n",
    "                    else: failed.append(t)\n",
    "                except Exception:\n",
    "                    failed.append(t)\n",
    "                finally:\n",
    "                    pbar.update(1)\n",
    "\n",
    "        await asyncio.gather(*[worker(t) for t in tasks])\n",
    "    pbar.close()\n",
    "    return success, failed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9408f3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "downloading images: 100%|██████████| 1966/1966 [01:18<00:00, 25.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Downloaded OK: 1948 / Planned: 1966\n",
      "Total URLs in CSV: 1966 (some may already exist on disk)\n",
      "\n",
      "Failed samples (showing up to 10):\n",
      "- fb5af385-aee6-568c-a22f-e6b90ef92dac 3 https://m.media-amazon.com/images/G/01/HIT/ImageBlockDimension/dimensions_SS522_.png\n",
      "- 599c5d85-f15d-57ee-a301-30da352c2013 6 https://m.media-amazon.com/images/G/01/HIT/ImageBlockDimension/dimensions_SS522_.png\n",
      "- 72675ea3-0e2e-5752-a1fb-61a1a3031f4e 6 https://m.media-amazon.com/images/G/01/HIT/ImageBlockDimension/dimensions_SS522_.png\n",
      "- 579657ef-e010-5fb7-b301-a50db999bba7 7 https://m.media-amazon.com/images/G/01/HIT/ImageBlockDimension/dimensions_SS522_.png\n",
      "- 9b0e0b55-3984-5624-9bb6-3552bb4d262f 6 https://m.media-amazon.com/images/G/01/HIT/ImageBlockDimension/dimensions_SS522_.png\n",
      "- ed575bc1-c87c-51f4-b34b-a7b64b1b70f3 4 https://m.media-amazon.com/images/G/01/HIT/ImageBlockDimension/dimensions_SS522_.png\n",
      "- c5ab3463-5b96-5d58-9f88-8175cdea76a3 6 https://m.media-amazon.com/images/G/01/HIT/ImageBlockDimension/dimensions_SS522_.png\n",
      "- a1bea533-d1c0-5471-a08a-c0619d61a519 7 https://m.media-amazon.com/images/G/01/HIT/ImageBlockDimension/dimensions_SS522_.png\n",
      "- a15f5945-e1cb-5f94-a589-e5f31cbe5619 7 https://m.media-amazon.com/images/G/01/HIT/ImageBlockDimension/dimensions_SS522_.png\n",
      "- 43c50c14-4d58-5d73-af00-792060e66446 5 https://m.media-amazon.com/images/G/01/HIT/ImageBlockDimension/dimensions_SS522_.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if not tasks:\n",
    "    print(\"Nothing to download (all files already exist).\")\n",
    "else:\n",
    "    ok, failed = asyncio.run(run_download(tasks, concurrency=32, per_host=8, timeout_s=30))\n",
    "    print(f\"\\nDownloaded OK: {ok} / Planned: {len(tasks)}\")\n",
    "    print(f\"Total URLs in CSV: {total_expected} (some may already exist on disk)\")\n",
    "    if failed:\n",
    "        print(\"\\nFailed samples (showing up to 10):\")\n",
    "        for t in failed[:10]:\n",
    "            print(\"-\", t.uniq_id, t.idx, t.url)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d6bd59",
   "metadata": {},
   "source": [
    "# EMBEDDINGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b73db3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, ast, re, glob, io\n",
    "from typing import List, Dict, Any, Tuple\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from tqdm.auto import tqdm\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# --- REQUIRED ENV ---\n",
    "PINECONE_API_KEY     = os.getenv(\"PINECONE_API_KEY\")\n",
    "PINECONE_ENV         = os.getenv(\"PINECONE_ENV\", \"us-east-1-aws\")\n",
    "PINECONE_TEXT_INDEX  = os.getenv(\"PINECONE_TEXT_INDEX\", \"products-text\")\n",
    "PINECONE_IMAGE_INDEX = os.getenv(\"PINECONE_IMAGE_INDEX\", \"products-image\")  # can be unused if no images\n",
    "\n",
    "CSV_PATH   = os.getenv(\"CSV_PATH\", \"intern_data_ikarus.csv\")\n",
    "IMAGE_DIR  = os.getenv(\"IMAGE_DIR\", \"./data/images_all\")  # pre-downloaded, one folder per uniq_id\n",
    "\n",
    "assert PINECONE_API_KEY, \"Missing PINECONE_API_KEY in .env\"\n",
    "assert os.path.exists(CSV_PATH), f\"CSV not found at {CSV_PATH}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "67ec44e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(312, ['uniq_id', 'title', 'brand', 'description', 'price'])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Expected schema\n",
    "expected_cols = [\n",
    "    \"uniq_id\",\"title\",\"brand\",\"description\",\"price\",\"categories\",\"images\",\n",
    "    \"manufacturer\",\"package_dimensions\",\"country_of_origin\",\"material\",\"color\"\n",
    "]\n",
    "\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "for c in expected_cols:\n",
    "    if c not in df.columns:\n",
    "        df[c] = pd.NA\n",
    "df = df[expected_cols].copy()\n",
    "\n",
    "def to_list(x):\n",
    "    if pd.isna(x): return []\n",
    "    s = str(x).strip()\n",
    "    if s.startswith(\"[\"):\n",
    "        try:\n",
    "            return list(ast.literal_eval(s))\n",
    "        except Exception:\n",
    "            pass\n",
    "    return [u.strip() for u in s.split(\",\") if u.strip()]\n",
    "\n",
    "def to_float(x):\n",
    "    if pd.isna(x): return pd.NA\n",
    "    s = str(x).replace(\",\", \"\").replace(\"₹\", \"\").strip()\n",
    "    m = re.findall(r\"[-+]?\\d*\\.?\\d+\", s)\n",
    "    return float(m[0]) if m else pd.NA\n",
    "\n",
    "df[\"categories\"] = df[\"categories\"].apply(to_list)\n",
    "df[\"images\"]     = df[\"images\"].apply(to_list)\n",
    "df[\"price\"]      = df[\"price\"].apply(to_float)\n",
    "\n",
    "len(df), df.columns.tolist()[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1b62cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Products with local images: 305\n"
     ]
    }
   ],
   "source": [
    "# Build a mapping uniq_id -> list of local image file paths (already downloaded earlier)\n",
    "uid_to_imgs: Dict[str, List[str]] = {}\n",
    "if os.path.isdir(IMAGE_DIR):\n",
    "    for uid in os.listdir(IMAGE_DIR):\n",
    "        folder = os.path.join(IMAGE_DIR, uid)\n",
    "        if not os.path.isdir(folder):\n",
    "            continue\n",
    "        imgs = sorted(\n",
    "            p for p in glob.glob(os.path.join(folder, \"*\"))\n",
    "            if os.path.splitext(p)[1].lower() in (\".jpg\",\".jpeg\",\".png\",\".webp\")\n",
    "        )\n",
    "        if imgs:\n",
    "            uid_to_imgs[str(uid)] = imgs\n",
    "\n",
    "print(\"Products with local images:\", len(uid_to_imgs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "63649be7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(384, 512, 'cpu')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cell 4 — Load Embedders (robust dim detection; GPU if available)\n",
    "import torch, numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from PIL import Image\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Text encoder (384-d): small, strong for metadata\n",
    "text_model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\", device=device)\n",
    "\n",
    "# Image encoder via CLIP; averages multiple images per product\n",
    "img_model  = SentenceTransformer(\"clip-ViT-B-32\", device=device)\n",
    "\n",
    "def _safe_dim_for_text(model) -> int:\n",
    "    vec = model.encode([\"dimension probe\"], normalize_embeddings=True, convert_to_numpy=True)\n",
    "    # vec shape: (1, D)\n",
    "    return int(vec.shape[-1])\n",
    "\n",
    "def _safe_dim_for_image(model) -> int:\n",
    "    # tiny black image probe\n",
    "    probe = Image.fromarray(np.zeros((224, 224, 3), dtype=np.uint8))\n",
    "    vec = model.encode([probe], normalize_embeddings=True, convert_to_numpy=True)\n",
    "    # vec shape: (1, D)\n",
    "    return int(vec.shape[-1])\n",
    "\n",
    "TEXT_DIM = _safe_dim_for_text(text_model)   # expected 384\n",
    "IMG_DIM  = _safe_dim_for_image(img_model)   # expected 512\n",
    "\n",
    "TEXT_DIM, IMG_DIM, device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1c1f30f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "\n",
    "existing = [ix[\"name\"] for ix in pc.list_indexes()]\n",
    "if PINECONE_TEXT_INDEX not in existing:\n",
    "    pc.create_index(\n",
    "        name=PINECONE_TEXT_INDEX,\n",
    "        dimension=TEXT_DIM,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
    "    )\n",
    "if PINECONE_IMAGE_INDEX not in existing:\n",
    "    pc.create_index(\n",
    "        name=PINECONE_IMAGE_INDEX,\n",
    "        dimension=IMG_DIM,\n",
    "        metric=\"cosine\",\n",
    "        spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
    "    )\n",
    "\n",
    "text_index  = pc.Index(PINECONE_TEXT_INDEX)\n",
    "image_index = pc.Index(PINECONE_IMAGE_INDEX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "08ad74c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6 — Helpers: Build Text & Metadata (robust to missing/empty values)\n",
    "\n",
    "def _safe_float(x, default=0.0):\n",
    "    # Accepts float/int/str/None/NaN and returns a float\n",
    "    try:\n",
    "        if x is None:\n",
    "            return float(default)\n",
    "        # If already numeric:\n",
    "        if isinstance(x, (int, float)):\n",
    "            return float(x)\n",
    "        s = str(x).strip()\n",
    "        if s == \"\" or s.lower() == \"nan\" or s.lower() == \"none\":\n",
    "            return float(default)\n",
    "        # extract first numeric token if needed\n",
    "        import re\n",
    "        m = re.findall(r\"[-+]?\\d*\\.?\\d+\", s)\n",
    "        return float(m[0]) if m else float(default)\n",
    "    except Exception:\n",
    "        return float(default)\n",
    "\n",
    "def product_text(row: pd.Series) -> str:\n",
    "    cats = \", \".join(row[\"categories\"]) if isinstance(row[\"categories\"], list) else \"\"\n",
    "    parts = [\n",
    "        f\"Title: {row['title']}\" if pd.notna(row['title']) else \"\",\n",
    "        f\"Brand: {row['brand']}\" if pd.notna(row['brand']) else \"\",\n",
    "        f\"Category: {cats}\" if cats else \"\",\n",
    "        f\"Material: {row['material']}\" if pd.notna(row['material']) and str(row['material']).strip() else \"\",\n",
    "        f\"Color: {row['color']}\" if pd.notna(row['color']) and str(row['color']).strip() else \"\",\n",
    "        f\"Country: {row['country_of_origin']}\" if pd.notna(row['country_of_origin']) and str(row['country_of_origin']).strip() else \"\",\n",
    "        f\"Price: {_safe_float(row['price'])}\" if pd.notna(row['price']) else \"\",\n",
    "        f\"Description: {row['description']}\" if pd.notna(row['description']) and str(row['description']).strip() else \"\",\n",
    "    ]\n",
    "    return \" | \".join([p for p in parts if p and str(p).strip() != \"\"])\n",
    "\n",
    "def meta_from_row(row: pd.Series) -> Dict[str, Any]:\n",
    "    cats = row[\"categories\"] if isinstance(row[\"categories\"], list) else []\n",
    "    return {\n",
    "        \"uniq_id\": str(row[\"uniq_id\"]),\n",
    "        \"title\": \"\" if not pd.notna(row[\"title\"]) else str(row[\"title\"]),\n",
    "        \"brand\": \"\" if not pd.notna(row[\"brand\"]) else str(row[\"brand\"]),\n",
    "        \"price\": _safe_float(row[\"price\"], default=0.0),\n",
    "        \"categories\": cats,\n",
    "        \"material\": \"\" if not pd.notna(row[\"material\"]) else str(row[\"material\"]),\n",
    "        \"color\": \"\" if not pd.notna(row[\"color\"]) else str(row[\"color\"]),\n",
    "        \"country_of_origin\": \"\" if not pd.notna(row[\"country_of_origin\"]) else str(row[\"country_of_origin\"]),\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "4f68d48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "text embed + upsert: 100%|██████████| 3/3 [00:14<00:00,  4.99s/it]\n"
     ]
    }
   ],
   "source": [
    "BATCH = 128\n",
    "rows = df.fillna(\"\").to_dict(orient=\"records\")\n",
    "\n",
    "def chunks(it, n):\n",
    "    for i in range(0, len(it), n):\n",
    "        yield it[i:i+n]\n",
    "\n",
    "for batch in tqdm(list(chunks(rows, BATCH)), desc=\"text embed + upsert\"):\n",
    "    texts = [product_text(pd.Series(r)) for r in batch]\n",
    "    vecs = text_model.encode(texts, normalize_embeddings=True).tolist()\n",
    "    to_upsert = []\n",
    "    for r, v in zip(batch, vecs):\n",
    "        to_upsert.append({\n",
    "            \"id\": str(r[\"uniq_id\"]),\n",
    "            \"values\": v,\n",
    "            \"metadata\": meta_from_row(pd.Series(r))\n",
    "        })\n",
    "    text_index.upsert(vectors=to_upsert, namespace=\"default\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f016002",
   "metadata": {},
   "source": [
    "# image embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e467e3cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image embed + upsert: 100%|██████████| 5/5 [02:12<00:00, 26.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image embeddings upserted: 312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if image_index is not None:\n",
    "    MAX_IMG = 8  # cap per product to control runtime/memory\n",
    "\n",
    "    def embed_images(paths: List[str]) -> np.ndarray | None:\n",
    "        ims = []\n",
    "        for p in paths:\n",
    "            try:\n",
    "                im = Image.open(p).convert(\"RGB\")\n",
    "                ims.append(im)\n",
    "            except Exception:\n",
    "                pass\n",
    "        if not ims:\n",
    "            return None\n",
    "        embs = img_model.encode(ims, normalize_embeddings=True, convert_to_numpy=True)  # (n, 512)\n",
    "        vec = embs.mean(axis=0)\n",
    "        vec = vec / (np.linalg.norm(vec) + 1e-12)\n",
    "        return vec.astype(np.float32)\n",
    "\n",
    "    uid_list = df[\"uniq_id\"].astype(str).tolist()\n",
    "    to_process: List[Tuple[str, List[str]]] = []\n",
    "    for uid in uid_list:\n",
    "        imgs = uid_to_imgs.get(uid, [])\n",
    "        if imgs:\n",
    "            to_process.append((uid, imgs[:MAX_IMG]))\n",
    "\n",
    "    BATCH_IMG = 64\n",
    "    total_upserts = 0\n",
    "    for chunk in tqdm(list(chunks(to_process, BATCH_IMG)), desc=\"image embed + upsert\"):\n",
    "        upserts = []\n",
    "        for uid, paths in chunk:\n",
    "            vec = embed_images(paths)\n",
    "            if vec is None:\n",
    "                continue\n",
    "            row = df.loc[df[\"uniq_id\"].astype(str) == uid].iloc[0]\n",
    "            upserts.append({\n",
    "                \"id\": uid,\n",
    "                \"values\": vec.tolist(),\n",
    "                \"metadata\": meta_from_row(row),\n",
    "            })\n",
    "        if upserts:\n",
    "            image_index.upsert(vectors=upserts, namespace=\"default\")\n",
    "            total_upserts += len(upserts)\n",
    "\n",
    "    print(\"Image embeddings upserted:\", total_upserts)\n",
    "else:\n",
    "    print(\"Skipping image embeddings (no image_index or no local images).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "dda89b4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXT query results:\n",
      "0.5897 | CangLong Mid Century Modern Side Chair with Wood Legs for Kitchen, Living Dining Room, Set of 1, Black — CangLong Store — ₹0.0\n",
      "0.5895 | Leather At Home, Decorative 13 Inch Rounded Pillow Handmade from Full Grain Leather - Chair Seat, Confortable Sitting for Round Wooden/Metal Stools - Bourbon Brown — Leather At Home Store — ₹26.49\n",
      "0.5858 | Armen Living Julius 30\" Cream Faux Leather and Walnut Wood Bar Stool — Armen Living Store — ₹0.0\n",
      "0.5667 | Christopher Knight Home Munro Recliner, Navy Blue + Teak — Christopher Knight Home Store — ₹0.0\n",
      "0.5644 | Adeco Euro Style Fabric Arm Bench Chair Footstool Cubic Ottomans, Brown — Adeco Store — ₹0.0\n",
      "\n",
      "IMAGE query results (probe: 000_237f60e9.jpg )\n",
      "0.9631 | GOYMFK 1pc Free Standing Shoe Rack, Multi-layer Metal Shoe Cap Rack With 8 Double Hooks For Living Room, Bathroom, Hallway — GOYMFK\n",
      "0.9284 | sogesfurniture 5 Tier Free Standing Wooden Shoe Storage Shelf Shoe Organizer, 29.5 inches Shoe Rack Shoe Organizer Storage Cabinet for Entryway, Living Room, Hallway, Doorway, Black — sogesfurniture Store\n",
      "0.9062 | SogesHome Wood Corner Cabinet Wall Corner Storage Cabinet, Storage Display Table Stand Cabinet, with Doors and Open Shelf, for Small Places, Living Room, White&Teak — SogesHome Store\n",
      "0.9026 | 3-Tier Side Table,Narrow End Table with Storage Shelf,Minimalist Bedside Tables Nightstand,Small Bookshelf Bookcase for Spaces,Bathroom Shelve,Display Rack for Bedroom,Living Room,Office,Dorms,2 Pack — HomeToDou\n",
      "0.9013 | Hzuaneri Blanket Ladder Shelf for Living Room, Decorative Wood Quilt Rack with 4 Removable Hooks, 5-Tier Farmhouse Ladder Holder Organizer for Bedroom, Rustic Brown 02101BBR — Hzuaneri Store\n"
     ]
    }
   ],
   "source": [
    "# TEXT → TEXT query\n",
    "query_text = \"modern wooden dining chair under 6000, natural finish\"\n",
    "qv = text_model.encode([query_text], normalize_embeddings=True, convert_to_numpy=True)[0].tolist()\n",
    "res = text_index.query(vector=qv, top_k=5, include_metadata=True, namespace=\"default\")\n",
    "\n",
    "print(\"TEXT query results:\")\n",
    "for m in res.get(\"matches\", []):\n",
    "    md = m.get(\"metadata\", {})\n",
    "    print(f\"{m.get('score',0):.4f} | {md.get('title')} — {md.get('brand')} — ₹{md.get('price')}\")\n",
    "\n",
    "# IMAGE → IMAGE query (only if we have images locally and image_index exists)\n",
    "if image_index is not None and uid_to_imgs:\n",
    "    sample_uid = next(iter(uid_to_imgs))\n",
    "    probe_path = uid_to_imgs[sample_uid][0]\n",
    "    im = Image.open(probe_path).convert(\"RGB\")\n",
    "    iv = img_model.encode([im], normalize_embeddings=True, convert_to_numpy=True)[0].tolist()\n",
    "\n",
    "    res2 = image_index.query(vector=iv, top_k=5, include_metadata=True, namespace=\"default\")\n",
    "    print(\"\\nIMAGE query results (probe:\", os.path.basename(probe_path), \")\")\n",
    "    for m in res2.get(\"matches\", []):\n",
    "        md = m.get(\"metadata\", {})\n",
    "        print(f\"{m.get('score',0):.4f} | {md.get('title')} — {md.get('brand')}\")\n",
    "else:\n",
    "    print(\"\\n(No image query performed.)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef6a06d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coco",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
